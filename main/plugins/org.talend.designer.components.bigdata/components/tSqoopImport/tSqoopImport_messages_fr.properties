LONG_NAME=Importe une table individuelle d'un SGBDR vers HDFS
EXTERNAL.NAME=Import Sqoop
TEMPFILE.NAME=Chemin du r\u00E9pertoire des donn\u00E9es temporaires
CONNECTION.NAME=Connexion
TABLE.NAME=Nom de la table
USERNAME.NAME=Utilisateur
PASSWORD.NAME=Mot de passe
USE_COLUMNS.NAME=Sp\u00E9cifier les colonnes
COLUMNS.NAME=Colonnes
COLUMNS.ITEM.COLUMN=Colonne
USE_WHERE.NAME=Utiliser la clause WHERE
PRINT_LOG.NAME=Afficher le log
VERBOSE.NAME=Verbose
USE_MAPPERS.NAME=Sp\u00E9cifier le nombre de mappers
USE_TARGET.NAME=Sp\u00E9cifier le r\u00E9pertoire cible
APPEND.NAME=Ecrire apr\u00E8s
DIRECT.NAME=Direct
COMPRESS.NAME=Compresser
FILE_FORMAT.NAME=Format du fichier
FILE_FORMAT.ITEM.textfile=TEXTFILE
FILE_FORMAT.ITEM.sequencefile=sequencefile
MYSQL_DELIMITERS.NAME=Utiliser les s\u00E9parateurs MySQL par d\u00E9faut
ADDITIONAL.NAME=Arguments suppl\u00E9mentaires
OUTPUT_MESSAGE.NAME=Message de sortie
USE_QUERY.NAME=Utiliser la requ\u00EAte
QUERY.NAME=Requ\u00EAte
ADDITIONAL_JAVA.NAME=Arguments suppl\u00E9mentaires
ADDITIONAL_JAVA.ITEM.ADDITIONAL_ARGUMENT=Argument
ADDITIONAL_JAVA.ITEM.ADDITIONAL_VALUE=Valeur
MODE.NAME=Mode
USE_JAVAAPI.NAME=Utiliser API Java
VERSION.NAME=Version
DISTRIBUTION.NAME=Distribution
DISTRIBUTION.ITEM.HORTONWORKS=HortonWorks
DISTRIBUTION.ITEM.CLOUDERA=Cloudera
DISTRIBUTION.ITEM.MAPR=MapR
DB_VERSION.NAME=Version de Hadoop
DB_VERSION.ITEM.MapR2=MapR 2.0.0
DB_VERSION.ITEM.HDP_1_2=Hortonworks Data Platform V1.2.0(Bimota)
DB_VERSION.ITEM.Cloudera_CDH4=Cloudera CDH4.X (MR 1 mode)
FS_DEFAULT_NAME.NAME=URI du NameNode
MAPRED_JOB_TRACKER.NAME=H\u00F4te du JobTracker
CONFIGURATION.NAME=Configuration
SPECIFIC_PARAMS.NAME=Param\u00E8tres Spark
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM=Argument
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-method=teradata.db.input.method
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-stage-database=teradata.db.input.stage.database
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-partition-num=teradata.db.input.partition.num
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-batch-size=teradata.db.input.batch.size
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM_VALUE=Valeur
SPEED_PARALLEL.NAME=Configuration sp\u00E9cifique du connecteur
DB_VERSION.ITEM.MAPR212=MapR 2.1.2 (Sqoop 1.4.2)
DISTRIBUTION.ITEM.CUSTOM=Personnalis\u00E9 - Non support\u00E9
DB_VERSION.ITEM.HDP_1_3=Hortonworks Data Platform V1.3.0(Condor)
HADOOP_ADVANCED_PROPERTIES.NAME=Propri\u00E9t\u00E9s Hadoop
HADOOP_ADVANCED_PROPERTIES.ITEM.PROPERTY=Propri\u00E9t\u00E9
HADOOP_ADVANCED_PROPERTIES.ITEM.VALUE=Valeur
DISTRIBUTION.ITEM.PIVOTAL_HD=Pivotal HD
DB_VERSION.ITEM.MAPR213=MapR 2.1.3 (Sqoop 1.4.2)
DB_VERSION.ITEM.HDP_2_0=Hortonworks Data Platform V2.0.0 (BigWheel)
DB_VERSION.ITEM.PIVOTAL_HD_1_0_1=Pivotal HD 1.0.1
USE_KRB.NAME=Utiliser l'authentification Kerberos
NAMENODE_PRINCIPAL.NAME=Principal du NameNode
JOBTRACKER_PRINCIPAL.NAME=Principal du JobTracker
USE_KEYTAB.NAME=Utiliser un Keytab pour l'authentification
PRINCIPAL.NAME=Principal
KEYTAB_PATH.NAME=Keytab
AUTHENTICATION.NAME=Authentification
USE_YARN.NAME=Utiliser YARN
RESOURCE_MANAGER.NAME=Gestionnaire de ressources
CLASSPATH_SEPARATOR.NAME=S\u00E9parateur de chemins sur le serveur
DB_VERSION.ITEM.MAPR301=MapR 3.0.1 (Sqoop 1.4.2)
DB_VERSION.ITEM.Cloudera_CDH4_YARN=Cloudera CDH4.3+ (mode YARN)
USE_ADDITION_PARAM.NAME=Utiliser param\u00E8tres suppl.
SPECIFIC_ADDITION_PARAM.NAME=Param\u00E8tres sp\u00E9cifiques suppl\u00E9mentaires
MEMORY_PARAMETERS.NAME=Param\u00E8tres de m\u00E9moire du Job
SET_MEMORY.NAME=Configurer la m\u00E9moire
MAPREDUCE_MAP_MEMORY_MB.NAME=Map (en Mo)
MAPREDUCE_REDUCE_MEMORY_MB.NAME=Reduce (en Mo)
YARN_APP_MAPREDUCE_AM_RESOURCE_MB.NAME=ApplicationMaster (en Mo)
HADOOP_USER.NAME=Utilisateur Hadoop
DB_VERSION.ITEM.MAPR310=MapR 3.1.0 (Sqoop 1.4.2)
DB_VERSION.ITEM.HDP_2_1=Hortonworks Data Platform V2.1.0 (Baikal)
DB_VERSION.ITEM.Cloudera_CDH5=Cloudera CDH5.0 (mode YARN)
DB_VERSION.ITEM.PIVOTAL_HD_2_0=Pivotal HD 2.0
SET_STAGING_DIRECTORY.NAME=D\u00E9finir le r\u00E9pertoire de pr\u00E9paration
JDBC_PROPERTY.NAME=Propri\u00E9t\u00E9 JDBC
HADOOP_PROPERTY.NAME=Propri\u00E9t\u00E9 Hadoop
COMMON_SQOOP_OPTIONS.NAME=Arguments communs
PASSWORD_STORED_IN_FILE.NAME=Le mot de passe est stock\u00E9 dans un fichier
PASSWORD_FILE.NAME=Chemin du fichier
DRIVER_JAR.NAME=Jar du pilote
DRIVER_JAR.ITEM.JAR_NAME=Nom du Jar
DEFINE_DIRECT_SPLIT_SIZE.NAME=Diviser le flux d'entr\u00E9e tous les N octets
DEFINE_HADOOP_CODEC.NAME=Utiliser le codec Hadoop
DELETE_TARGET_DIR.NAME=Supprimer le r\u00E9pertoire cible
FILE_FORMAT.ITEM.avrofile=Fichier Avro
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT=Argument
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_VALUE=Valeur
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--bindir=bindir
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--boundary-query=--boundary-query
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--class-name=--class-name
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--column-family=--column-family
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--connection-manager=--connection-manager
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--create-hcatalog-table=--create-hcatalog-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--create-hive-table=--create-hive-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--driver=--driver
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--direct-split-size=--direct-split-size
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--enclosed-by=--enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--escaped-by=--escaped-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--fetch-size=--fetch-size
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--fields-terminated-by=--fields-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hadoop-mapred-home=--hadoop-mapred-home
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hadoop-home=--hadoop-home
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hbase-create-table=--hbase-create-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hbase-row-key=--hbase-row-key
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hbase-table=--hbase-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hcatalog-database=--hcatalog-database
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hcatalog-home=--hcatalog-home
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hcatalog-storage-stanza=--hcatalog-storage-stanza
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hcatalog-table=--hcatalog-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-delims-replacement=--hive-delims-replacement
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-drop-import-delims=--hive-drop-import-delims
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-home=--hive-home
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-import=--hive-import
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-overwrite=--hive-overwrite
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-partition-key=--hive-partition-key
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-partition-value=--hive-partition-value
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-table=--hive-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--inline-lob-limit=--inline-lob-limit
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-enclosed-by=--input-enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-escaped-by=--input-escaped-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-fields-terminated-by=--input-fields-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-lines-terminated-by=--input-lines-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-optionally-enclosed-by=--input-optionally-enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--jar-file=--jar-file
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--lines-terminated-by=--lines-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--null-non-string=--null-non-string
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--null-string=--null-string
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--optionally-enclosed-by=--optionally-enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--outdir=--outdir
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--package-name=--package-name
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--split-by=--split-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--warehouse-dir=--warehouse-dir
TYPE_MAPPING.NAME=Mapping de types
DEFINE_JAVA_MAPPING.NAME=D\u00E9finir le mapping Java
JAVA_TYPE_MAPPING.NAME=Mapping Java
JAVA_TYPE_MAPPING.ITEM.COLUMN_NAME=Nom de colonne
JAVA_TYPE_MAPPING.ITEM.JAVA_TYPE=Type Java
DEFINE_HIVE_MAPPING.NAME=D\u00E9finir le mapping Hive
HIVE_TYPE_MAPPING.NAME=Mapping Hive
HIVE_TYPE_MAPPING.ITEM.COLUMN_NAME=Nom de colonne
HIVE_TYPE_MAPPING.ITEM.HIVE_TYPE=Type Hive
CONTROL_SQOOP_OPTIONS.NAME=Importer les arguments de contr\u00F4le
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-file-format=teradata.db.input.file.format
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-job-type=teradata.db.input.job.type
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-num-mappers=teradata.db.input.num.mappers
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-num-partitions-in-staging=teradata.db.input.num.partitions.in.staging
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-separator=teradata.db.input.separator
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-source-count-query=teradata.db.input.source.count.query
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-source-field-names=teradata.db.input.source.field.names
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-source-query=teradata.db.input.source.query
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-source-table=teradata.db.input.source.table
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-split-by-column=teradata.db.input.split.by.column
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-stage-force=teradata.db.input.stage.force
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-stage-table-name=teradata.db.input.stage.table.name
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-target-database=teradata.db.input.target.database
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-target-field-names=teradata.db.input.target.field.names
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-target-partition-schema=teradata.db.input.target.partition.schema
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-target-table=teradata.db.input.target.table
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-target-table-schema=teradata.db.input.target.table.schema
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-target-paths=teradata.db.input.target.paths
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-teradata-db-hive-configuration-file=teradata.db.input.teradata.db.hive.configuration.file
DIE_ON_ERROR.NAME=Arr\u00EAter en cas d'erreur
DRIVER_CLASS.NAME=Nom de classe
DISTRIBUTION.ITEM.AMAZON_EMR=Amazon EMR
DB_VERSION.ITEM.MAPR401=MapR 4.0.1 (mode YARN)
DB_VERSION.ITEM.Cloudera_CDH5_1_MR1=Cloudera CDH5.1(mode MR 1)
DB_VERSION.ITEM.Cloudera_CDH5_1=Cloudera CDH5.1 (mode YARN)
DB_VERSION.ITEM.APACHE_2_4_0_EMR=Apache 2.4.0
USE_DATANODE_HOSTNAME.NAME=Utiliser le nom d'h\u00F4te du n\u0153ud de donn\u00E9es
EXIT_CODE.NAME=Code de sortie
DB_VERSION.ITEM.HDP_2_2=Hortonworks Data Platform V2.2.0
DB_VERSION.ITEM.Cloudera_CDH5_4=Cloudera CDH5.4 (mode YARN)
DB_VERSION.ITEM.MAPR410=MapR 4.1.0 (mode YARN)
DB_VERSION.ITEM.MAPR500=MapR 5.0.0 (mode YARN)
DB_VERSION.ITEM.HDP_2_3=Hortonworks Data Platform V2.3.2
USE_MAPRTICKET.NAME=Utiliser l'authentification par ticket MapR
MAPRTICKET_USERNAME.NAME=Utilisateur
MAPRTICKET_PASSWORD.NAME=Mot de passe
MAPRTICKET_CLUSTER.NAME=Nom du cluster
MAPRTICKET_DURATION.NAME=Dur\u00E9e du ticket (en s)
SET_HADOOP_LOGIN.NAME=D\u00E9finir la configuration de connexion \u00E0 Hadoop
AUTHENTICATION_MAPR.NAME=Ticket MapR d'authentification
FILE_FORMAT.ITEM.parquetfile=Fichier Parquet
